{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Clarify Logo](https://global-uploads.webflow.com/5e81e464dad44d3a9a32d1f4/5ed10fc3f1ff8467f4466786_logo.svg)\n",
    "\n",
    "# Google Cloud Hosting\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/searis/data-science-tutorials/main/media/docker/cloud.png\" alt=\"clarify doodle\" width=\"400\">\n",
    "\n",
    "In this tutorial, we will create a docker image and deploy it to Google Cloud. The docker image will use the [PyClarify](https://pypi.org/project/pyclarify/) package which provides a fast and easy way to get data from Clarify and write data back. For more details on how to use click [here](https://searis.github.io/pyclarify/) for the documentation. In the docker image, we will also use the [OpenWeather API](https://openweathermap.org/api) but feel free to use any API you prefer.\n",
    "\n",
    "## Prerequisites\n",
    "It is highly recommended that you have gone through the [Introduction Notebook](https://colab.research.google.com/github/searis/data-science-tutorials/blob/main/tutorials/Introduction.ipynb) for the basics of using PyClarify. This tutorial is will not go into details about how to use PyClarify. Basic knowledge of docker is also preferable since this tutorial does not aim to show you how docker works, but how to use it with Clarify.\n",
    "\n",
    "## What do you need\n",
    "1. [Your Credentails](https://colab.research.google.com/github/searis/data-science-tutorials/blob/main/tutorials/Introduction.ipynb#credentials)\n",
    "1. [Google Cloud Account](https://cloud.google.com/free)\n",
    "2. [Google Cloud SDK](https://cloud.google.com/sdk/docs/install)\n",
    "3. [Docker](https://www.docker.com/products/docker-desktop)\n",
    "\n",
    "## What we will do\n",
    "1. [Choose an API from where you will get your data](#api)\n",
    "2. [Integrating with Clarify](#integration)\n",
    "3. [Create a docker image](#image)\n",
    "4. [Google Cloud Hosting](#hosting)\n",
    "5. [See results in Clarify](#clarify)\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "Other resources:\n",
    "- [PyClarify documentation](https://searis.github.io/pyclarify/)\n",
    "- [Clarify Developer documentation](https://docs.clarify.io/reference/http)\n",
    "- [Introduction Notebook](https://colab.research.google.com/github/searis/data-science-tutorials/blob/main/tutorials/Introduction.ipynb)\n",
    "- [Google Cloud Platform](https://cloud.google.com)\n",
    "- [OpenWeather API](https://openweathermap.org)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "The first step is to download your credentials and upload the file to this workspace. Click [here](https://colab.research.google.com/github/searis/data-science-tutorials/blob/main/tutorials/Introduction.ipynb#credentials) for how to do it.\n",
    "\n",
    "After that, download [Docker](https://www.docker.com/products/docker-desktop) and [Google Cloud SDK](https://cloud.google.com/sdk/docs/install).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"api\"></a>\n",
    "# Choose an API from where you will get your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use the free [OpenWeather API](https://openweathermap.org/api). To use this API the only thing you need is an API key. To get this key you need to sign in [here](https://home.openweathermap.org/users/sign_up). After you sign in you will receive an email with your API key. For more details, you can read the [OpenWeather API documentation](https://openweathermap.org/appid).\n",
    "\n",
    "To understand how the OpenWeather API works and what data we will use, you can run the cell below. Add your API key and specify a city of your choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "# provide your key\n",
    "API_key = \"<your-API-key>\"\n",
    "\n",
    "# specify a city from which you will recieve weather data, for example Trondheim\n",
    "city_name = \"Trondheim\"\n",
    "\n",
    "# make a get request\n",
    "url = f\"https://api.openweathermap.org/data/2.5/weather?q={city_name}&appid={API_key}&units=metric\"\n",
    "response_data = requests.get(url).json()\n",
    "\n",
    "print(response_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [response](https://openweathermap.org/current#parameter) will look something like this: \n",
    "\n",
    "```json\n",
    "\n",
    "{\n",
    "    \"coord\": {\"lon\": 10.3951, \"lat\": 63.4305},\n",
    "    \"weather\": [\n",
    "        {\n",
    "            \"id\": 803,                                    -> id\n",
    "            \"main\": \"Clouds\",                             -> main\n",
    "            \"description\": \"broken clouds\",\n",
    "            \"icon\": \"04d\",                               \n",
    "        }\n",
    "    ],\n",
    "    \"base\": \"stations\",\n",
    "    \"main\": {\n",
    "        \"temp\": 4.05,                                     -> temp\n",
    "        \"feels_like\": 1.45,\n",
    "        \"temp_min\": 3.64,\n",
    "        \"temp_max\": 7.05,\n",
    "        \"pressure\": 1021,\n",
    "        \"humidity\": 90,\n",
    "    },\n",
    "    \"visibility\": 10000,\n",
    "    \"wind\": {\"speed\": 2.89, \"deg\": 230, \"gust\": 4.39},\n",
    "    \"clouds\": {\"all\": 63},\n",
    "    \"dt\": 1634544451,\n",
    "    \"sys\": {\n",
    "        \"type\": 2,\n",
    "        \"id\": 131520,\n",
    "        \"country\": \"NO\",\n",
    "        \"sunrise\": 1634537710,\n",
    "        \"sunset\": 1634572297,\n",
    "    },\n",
    "    \"timezone\": 7200,                                     \n",
    "    \"id\": 3133880,\n",
    "    \"name\": \"Trondheim\",\n",
    "    \"cod\": 200,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this response, we will only use `id` and `temp` (temperature).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from API\n",
    "temperature = response_data[\"main\"][\"temp\"]\n",
    "weather_condition_enum_number = response_data[\"weather\"][0][\"id\"]\n",
    "values = [temperature, weather_condition_enum_number]\n",
    "\n",
    "print(f\"temperature: {temperature}, weather_condition_enum_number: {weather_condition_enum_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"integration\"></a>\n",
    "# Integrating with Clarify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/searis/data-science-tutorials/main/media/docker/clarify.png\" alt=\"clarify image\">\n",
    "\n",
    "## Create signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start writing data to Clarify, we will first create two signals with metadata. One signal is for the temperature values and the other signal is for the weather conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclarify import ClarifyClient, SignalInfo\n",
    "\n",
    "client = ClarifyClient(\"./clarify-credentials.json\")\n",
    "\n",
    "INPUT_ID = [\"temperature_value\", \"weather_condition\"]\n",
    "\n",
    "signal_temperature_values = SignalInfo(\n",
    "    name = \"Temperature value\",\n",
    "    type = \"numeric\",\n",
    "    description=\"Temperature from the OpenWeather API\",\n",
    "    labels={\"data-source\": [\"OpenWeather API\"], \"location\": [\"Trondheim\"]},\n",
    "    engUnit=\"°C\"\n",
    ")\n",
    "\n",
    "signal_temperature_enums = SignalInfo(\n",
    "    name = \"Weather condition\",\n",
    "    type = \"enum\",\n",
    "    description=\"Weather condition from the OpenWeather API\",\n",
    "    labels={\"data-source\": [\"OpenWeather API\"], \"location\": [\"Trondheim\"]},\n",
    ")\n",
    "response_save_signals = client.save_signals(input_ids = INPUT_ID, signals = [signal_temperature_values, signal_temperature_enums])\n",
    "print(response_save_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should be able to see the two signals in Clarify. Go to **Integrations**, click on the intergration you wrote the signals and go to **Show all signals**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enums\n",
    "\n",
    "Before creating an item from a signal, we will add some metadata for the `weather_condition` signal. From the OpenWeather API [documentation](https://openweathermap.org/weather-conditions) under the *Weather condition codes* we see groups which in most cases share the same main value. \n",
    "\n",
    "We could specify for every ID the main value, but for simplicity reasons in this tutorial, we will only use 6 groups. For every `id` we extract the first number and correspond it to the value of the main. For example, if `id = 201` we will set the id to `2` and the main equal to `Thunderstorm`. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/searis/data-science-tutorials/main/media/docker/group.png\" alt=\"Weather condition codes\" width=\"400\">\n",
    "\n",
    "\n",
    "The 6 groups which we will use are:\n",
    "\n",
    "```JSON\n",
    "2: Thunderstorm,\n",
    "3: Drizzle,\n",
    "5: Rain,\n",
    "6: Snow,\n",
    "7: Atmosphere,\n",
    "8: Clouds\n",
    "```\n",
    "\n",
    "\n",
    "Enums values can be set using the Clarify UI or using the PyClarify SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1\n",
    "\n",
    "Using the User Interface in Clarify, you can specify the enum values.\n",
    "\n",
    "If the signal is unpublished, you can go to your Signal page and click on the signal you want to publish. From there you can add enum values.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/searis/data-science-tutorials/main/media/docker/add_enums.gif\" alt=\"Add enum values\" />\n",
    "\n",
    "A second way is to go to your Item page, click on an Item and from the metadata you can add or change the enum values.\n",
    "\n",
    "In this tutorial, we will use the UI in Clarify since it is a more generic and dynamic way. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2\n",
    "\n",
    "Saving enum values using the API can be done with the following code. \n",
    "\n",
    "> Note that here you assume that you know all the possible values of the enums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclarify import SignalInfo\n",
    "\n",
    "main = {\n",
    "    '2': 'Thunderstorm',\n",
    "    '3': 'Drizzle',\n",
    "    '5': 'Rain',\n",
    "    '6': 'Snow',\n",
    "    '7': 'Atmosphere',\n",
    "    '8': 'Clouds'\n",
    "}\n",
    "\n",
    "signal = SignalInfo(name=\"Weather condition\", type=\"enum\", enumValues=main)\n",
    "\n",
    "response_save_signals = client.save_signals(input_ids = [INPUT_ID[1]], signals=[signal])\n",
    "print(response_save_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data to Clarify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the PyClarify package we can write data to Clarify. For more information check out the [PyClarify documentation](https://searis.github.io/pyclarify/) and the [Introduction tutorial](https://colab.research.google.com/github/searis/data-science-tutorials/blob/main/tutorials/Introduction.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclarify import DataFrame\n",
    "from datetime import datetime\n",
    "\n",
    "# Get local time in ISO 8601\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S%Z\")\n",
    "current_time += \"Z\" # ADD UTC time offset\n",
    "\n",
    "# extract data from API\n",
    "temperature = response_data[\"main\"][\"temp\"]\n",
    "weather_condition_enum_number = int(str(response_data[\"weather\"][0][\"id\"])[0])\n",
    "values = [temperature, weather_condition_enum_number]\n",
    "\n",
    "# create a data frame model\n",
    "series = {}\n",
    "for input_id_, data_ in zip(INPUT_ID, values):\n",
    "    series[input_id_] = [data_]\n",
    "\n",
    "df = DataFrame(times=[current_time], series=series)\n",
    "\n",
    "# write signal data to Clarify\n",
    "response = client.insert(data=df)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"image\"></a> \n",
    "# Create a docker image\n",
    "\n",
    "Now we are ready to create our docker image, which will write data in a fixed interval to our signal that we created [previously](#signal).\n",
    "\n",
    "The folder structure which we want to create is the following:\n",
    "\n",
    "```\n",
    "docker/\n",
    "├── Dockerfile\n",
    "├── clarify-credentials.json\n",
    "├── app.py\n",
    "└── requirements.txt\n",
    "```\n",
    "\n",
    "Click [here](https://github.com/searis/data-science-tutorials/tree/main/tutorials/docker) to see the folder and files in the github repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a python server which will make our docker container run every 1 minute and return data.\n",
    "\n",
    "For this we will use [Flask](https://flask.palletsprojects.com/en/2.0.x/) and [Gunicorn](https://gunicorn.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `app.py` script.\n",
    "\n",
    "Here is an example code which will write data every minute to the `temperature_value` and `weather_condition` signal. The city from which we will get the weather data is Trondheim.\n",
    "\n",
    "Don't forget to specify your `API_KEY`.\n",
    "\n",
    "```python\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "from datetime import datetime\n",
    "from flask import Flask\n",
    "from pyclarifyimport APIClient, DataFrame\n",
    "import requests\n",
    "\n",
    "\n",
    "INPUT_ID = [\"temperature_value\", \"weather_condition\"]\n",
    "API_KEY = \"<your-API-key>\"\n",
    "CITY_NAME = \"Trondheim\" \n",
    "\n",
    "def main():\n",
    "   \n",
    "    client = APIClient(\"./clarify-credentials.json\")\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={CITY_NAME}&appid={API_KEY}&units=metric\"\n",
    "    response = requests.get(url).json()\n",
    "\n",
    "    # Get local time in ISO 8601\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S%Z\")\n",
    "    current_time += \"Z\" # ADD UTC time offset\n",
    "\n",
    "    # extract data from API\n",
    "    temperature = response[\"main\"][\"temp\"]\n",
    "    weather_condition_enum_number = int(str(response[\"weather\"][0][\"id\"])[0])\n",
    "    values = [temperature, weather_condition_enum_number]\n",
    "\n",
    "    # create a data frame model\n",
    "    series = {}\n",
    "    for input_id_, data_ in zip(INPUT_ID, values):\n",
    "        series[input_id_] = [data_]\n",
    "\n",
    "    df = DataFrame(times=[current_time], series=series)\n",
    "\n",
    "    # write signal data to Clarify\n",
    "    response = client.insert(data=df)\n",
    "    print(response)\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "sched = BackgroundScheduler(daemon=True)\n",
    "sched.add_job(main, 'interval', minutes=1)\n",
    "sched.start()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, host=\"0.0.0.0\", port=8080)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Dockerfile we use as a base image Python 3.9, we copy the requirements, the clarify credentials and our python script. We install the requirements file and run the [gunicorn](https://docs.gunicorn.org/en/latest/run.html) server. \n",
    "\n",
    "```bash \n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt clarify-credentials.json app.py ./\n",
    "\n",
    "RUN pip3 install -r requirements.txt\n",
    "\n",
    "CMD gunicorn --workers 1 --threads 8 --timeout 0 app:app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `requirements.txt` file and add the following:\n",
    "\n",
    "```\n",
    "pyclarify==0.1.0\n",
    "requests==2.26.0\n",
    "gunicorn==20.1.0\n",
    "Flask==2.0.2\n",
    "APScheduler==3.8.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test you image locally run\n",
    "\n",
    "```sh\n",
    "$ docker build -t YOUR-IMAGE-TAG .\n",
    "$ docker run YOUR-IMAGE-TAG\n",
    "```\n",
    "\n",
    "To stop you image run \n",
    "\n",
    "```sh \n",
    "$ docker ps\n",
    "```\n",
    "\n",
    "Copy the container-id \n",
    "\n",
    "```sh \n",
    "$ docker stop <container-id>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"hosting\"></a>\n",
    "# Google Cloud Hosting\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/searis/data-science-tutorials/main/media/docker/hosting.png\" alt=\"clarify image\" width=\"600\">\n",
    "\n",
    "Now that we have a working docker image, we can push it to a cloud environment. We will use the Google Cloud Run environment to host our docker image. Google has great guides on [adding your docker image to their registry](https://cloud.google.com/container-registry/docs/pushing-and-pulling) and [deploying it on their run service](https://cloud.google.com/run/docs/deploying#command-line). \n",
    "\n",
    "> Keep in mind that their systems may change in the future and their guides should be the source of truth!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have downloaded [Google Cloud SDK](https://cloud.google.com/sdk/docs/install) before we start. Check that it is installed correctly by running the `gcloud version`.\n",
    "\n",
    "Before we connect to your google account with the SDK, you can [create a project](https://console.cloud.google.com/projectcreate) so that we can connect to the project as well. If you have multiple Google Accounts, make sure that you are logged into the correct one.\n",
    "\n",
    "Once that is completed you can connect to your google account running `gcloud auth login` in the terminal. To make sure that you have set the correct account and project run `gcloud config list`.\n",
    "\n",
    "> To use `Container Registry` and `Cloud Run` environments make sure that you have enabled them both. \n",
    ">\n",
    ">* [Enable Container Registry API](https://console.developers.google.com/apis/api/containerregistry.googleapis.com)\n",
    ">* [Enable Cloud Run API](https://console.cloud.google.com/apis/library/run.googleapis.com) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish your image in the Container Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the first step we start by building the image and adding a `tag` to it:\n",
    "```sh\n",
    "$ docker build -t YOUR-IMAGE-TAG .\n",
    "```\n",
    "\n",
    "Now that we have a built image with a tag, we can set it's target path in [Container Registry](https://cloud.google.com/container-registry/docs/pushing-and-pulling#add-registry), including the gcr.io registry host and the project ID of `YOUR-PROJECT-ID`:\n",
    "\n",
    "```sh\n",
    "$ docker tag YOUR-IMAGE-TAG gcr.io/YOUR-PROJECT-ID/YOUR-IMAGE-TAG\n",
    "```\n",
    "\n",
    "The final step of publishing the image is to push it to the container registry. To do this run:\n",
    "\n",
    "```sh\n",
    "$ docker push gcr.io/YOUR-PROJECT-ID/YOUR-IMAGE-TAG\n",
    "```\n",
    "\n",
    "Now your image is published! The Container Registry adds the registry to your project, creates a storage bucket for the registry, and stores the image. For more information please refer to [their guides](https://cloud.google.com/container-registry/docs/pushing-and-pulling).\n",
    "\n",
    "\n",
    "Head over to the [Container Registry](https://console.cloud.google.com/gcr/images/) where you can verify that your image is there. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Cloud run services to run your image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1**\n",
    "\n",
    "To create a service in Cloud run you can either go to [Cloud Run](https://console.cloud.google.com/run) and create a service by clicking on the create service button. From there you can select your image URL, give a name for your service and specify a location. Under `Autoscaling`, set the `Minimum number of instances` and `Maximum number of instances` to 1 so that you always sending data to Clarify. Check the `Require authentication` button and click create.  \n",
    "\n",
    "> Google Cloud Run uses [autoscaling](https://cloud.google.com/run#all-features) which means that it scales from zero to N containers depending on the traffic received. This means that if your site receives no traffic it will scale down to zero instances after 15 minutes and thus stop sending data with the background scheduler. As this container's main purpose is to write data to Clarify with a background scheduler, we want it to be only one container at all times.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2**\n",
    "\n",
    "The same steps can be done by running the command: \n",
    "\n",
    "```sh\n",
    "$ gcloud run deploy YOUR-IMAGE-TAG --image gcr.io/YOUR-PROJECT-ID/YOUR-IMAGE-TAG --min-instances 1 --max-instances 1\n",
    "```\n",
    "\n",
    "After you run this command you will be asked two questions. They are pretty self-explanatory, but if you want to follow completely run:\n",
    "- 13 (for europe-north1 region)\n",
    "- N (to not allow unauthenticated invocations)\n",
    "\n",
    "Google provides a quickstart guide for building and deploying python services [here](https://cloud.google.com/run/docs/quickstarts/build-and-deploy/python).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"clarify\"></a>\n",
    "# See results in Clarify\n",
    "\n",
    "Time to see your data in a Timeline. Clarify provides a nice way to visualize your data clearly and easily. For more information about how to create a timeline in Clarify click [here](https://colab.research.google.com/github/searis/data-science-tutorials/blob/main/tutorials/Introduction.ipynb#bonus).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/searis/data-science-tutorials/main/media/docker/timeline.gif\" alt=\"Clarify Timeline\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to go next \n",
    "\n",
    "* [Forecasting](https://colab.research.google.com/github/clarify/data-science-tutorials/blob/main/tutorials/Forecasting.ipynb)\n",
    "* [Pattern Recognition](https://colab.research.google.com/github/searis/data-science-tutorials/blob/main/tutorials/Pattern%20Recognition.ipynb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ec01bbe28fab5d5ce8a245cdae6696070c21c8960a6b71595eceb1d9242d722"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('DS_tutorials': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
