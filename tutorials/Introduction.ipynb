{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGyEzsWLis9C"
      },
      "source": [
        "![Clarify Logo](https://global-uploads.webflow.com/5e81e464dad44d3a9a32d1f4/5ed10fc3f1ff8467f4466786_logo.svg)\n",
        "\n",
        "# Welcome to this basic tutorial on using Python with Clarify!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/clarify/data-science-tutorials/main/media/introduction/light.png\" alt=\"clarify doodle\" width=\"400\">\n",
        "\n",
        "\n",
        "## What you need\n",
        "\n",
        "1. A Clarify account (with admin rights)\n",
        "2. A working Integration with Signal(s)\n",
        "3. An Item (published Signal)\n",
        "\n",
        "## What we will do\n",
        "1. [Get credentials from Clarify](#credentials)\n",
        "2. [Read data from our APIs](#read)\n",
        "3. [Write data back to Clarify (as a signal)](#write)\n",
        "4. [Adding data to the new Signal](#process)\n",
        "5. [(Bonus) Visualise the data in Clarify](#bonus)\n",
        "\n",
        "--- \n",
        "Other resources:\n",
        "* [API reference](https://docs.clarify.io/reference/http)\n",
        "* [SDK documentation](https://clarify.github.io/pyclarify/)\n",
        "* [Intro to Python Notebooks](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G45s0wQKwN5"
      },
      "source": [
        "<a name=\"credentials\"></a>\n",
        "## Get credentials from Clarify\n",
        "\n",
        "First, you need to connect this notebook with your Clarify account. To do this, download your credentials from the admin panel in Clarify. \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/clarify/data-science-tutorials/main/media/introduction/get_credentials.gif\" alt=\"Getting credentials\">\n",
        "\n",
        "\n",
        "1. Access the admin panel you need to click on your organization (located on the top right corner) and go to the integrations menu.\n",
        "2. Click the integration containing your signal and toggle the `Access to item data`.\n",
        "3. Download the `clarify-credentials.json` file found in the `Credentials` tab.\n",
        "4. The final step is to upload the file to this workspace.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYHDIZHemDfW"
      },
      "source": [
        "<a name=\"read\"></a>\n",
        "## Read data from our APIs\n",
        "We will be using the PyClarify SDK for authentication, reading `Items` and writing `Signals` to the Clarify app. \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/clarify/data-science-tutorials/main/media/introduction/light-mono.png\" alt=\"clarify doodle\" width=\"400\">\n",
        "\n",
        "Run the block below to install the [PyClarify SDK](https://clarify.github.io/pyclarify/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZLi0pmmSKZW",
        "outputId": "a24f128d-82d1-4623-d36e-074dd72aeeb9"
      },
      "outputs": [],
      "source": [
        "!pip install pyclarify"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKcYNXWRm0qW"
      },
      "source": [
        "We will split reading items into two parts:\n",
        "* Reading the *meta data* information of your signals\n",
        "* Reading the *data* of your signals\n",
        "\n",
        "Due note that this can be done in a single request, however for this turorial we split them to simplify. \n",
        "\n",
        "The SDK is mirroring the Clarify API, thus [the reference document](https://docs.clarify.io/reference) will be a good resource if you come across any issues or want to see the capabilities of the API.\n",
        "\n",
        "To be able to read `Items`, we need to create a client to the API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc_0NantSKZW"
      },
      "outputs": [],
      "source": [
        "from pyclarify import APIClient\n",
        "#insert the file path to your credentials below\n",
        "client = APIClient(\"./clarify-credentials.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8u-s7zYn3cH"
      },
      "source": [
        "#### Reading Meta data\n",
        "Your items contain information about all sorts of stuff. This can be location of the item, the engineering unit it displays, the sample interval and so forth. You can actually [create your own labels](https://docs.clarify.io/reference#signal) and add whatever you want to keep your items neat and organised. We will explore that further in the [writing items section](#write). \n",
        "\n",
        "> The API has a default limit of displaying 10 items each request. Use the `skip` attribute to skip the x first `items`. You can also increase the `limit` to retrieve more items in a single query. \n",
        "\n",
        "For now we create an empty request:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJZi9YXvVr6g",
        "outputId": "5438ec9f-573f-4033-a9b5-30e464fd524a"
      },
      "outputs": [],
      "source": [
        "empty_request = {\n",
        "  \"items\": {\n",
        "    \"include\": True, \n",
        "    \"skip\": None,\n",
        "    \"limit\": None # Max limit is 50\n",
        "  }, \n",
        "  \"data\": {\n",
        "  }\n",
        "}\n",
        "\n",
        "# Send request to API\n",
        "response = client.select_items(empty_request)\n",
        "item_dict = response.result.items\n",
        "\n",
        "# Print result\n",
        "for item_id, meta_data in item_dict.items():\n",
        "  print(f\"ID: {item_id} \\t Name: {meta_data.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "793jjT6xpmll"
      },
      "source": [
        "Here you can see the name and ID of the `Items` your `clarify-credentials.json` have access to. \n",
        "\n",
        "The block below prints a complete list of meta data your last `Item` contains:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSGecH-Dp_vt",
        "outputId": "e3c15494-4001-426c-80c9-f82c8a8780fa"
      },
      "outputs": [],
      "source": [
        "for value in meta_data:\n",
        "  print(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63xdOnC0rksb"
      },
      "source": [
        "<a name=\"reading_values\"></a>\n",
        "#### Reading data\n",
        "To read the values of an `Item` we need to know the ID of it. For simplicity it is currently set to the last `Item` retrieved by the empty request. \n",
        "\n",
        "You can select any of the ids that are displayed above, by setting `item_id` manually.\n",
        "\n",
        "> The API currently only supports 40 days of data in a single request. Some `Items` might not have data in the last 40 days, thus there might be a need to manually set the start time of when to retrieve data. This can be done by specifying a `notBefore` variable in the request. You can also specify a `before` variable to set the ending time of the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkZXG6zOZ3hG",
        "outputId": "97ff4253-bfbd-4a72-e43e-f02e8fe6a632"
      },
      "outputs": [],
      "source": [
        "reading_data_request = {\n",
        "  \"items\": {\n",
        "    \"include\": False,\n",
        "    \"filter\": {\n",
        "      \"id\": {\n",
        "        \"$in\": [\n",
        "          item_id\n",
        "        ]\n",
        "      }\n",
        "    }\n",
        "  },\n",
        "  \"data\": {\n",
        "    \"include\": True,\n",
        "    \"notBefore\": \"2021-03-13T01:00:00Z\", #starting timestamp\n",
        "    \"before\": None #ending timestamp (default is 40 days from starting)\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "response = client.select_items(reading_data_request)\n",
        "data = response.result.data\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "224mPCe3aYWt"
      },
      "source": [
        "Clarify data frames have two attributes:\n",
        "* **times:** `List[datetime]` - A list of the shared timestamp of the retrieved `Items`. \n",
        "* **series:** `Dict[InputID, NumericalValuesType]` - A dictionary containing ids of `Items` as a key and a list of numerical values as values.\n",
        "\n",
        "> For more information of DataFrames in Clarify [see here](https://docs.clarify.io/reference/data-frame-1).\n",
        "\n",
        "For now, lets visualise the retrieved data with help of [the Plotly package](https://github.com/plotly/plotly.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxtn-RPPnPph",
        "outputId": "05d6fb66-8229-409f-ab61-f1118df27678"
      },
      "outputs": [],
      "source": [
        "pip install -U plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "HG4UzxwEb_iM",
        "outputId": "d7b32f96-60f7-41fb-b028-612e58a30362"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "item_name = meta_data.name\n",
        "times = data.times\n",
        "series = data.series\n",
        "values = series[item_id] \n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=times, y=values))\n",
        "fig.update_layout(title=item_name)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KInzZN6Ht97y"
      },
      "source": [
        "<a name=\"write\"></a>\n",
        "### Writing data back to Clarify\n",
        "Now that we have imported an Item to Notebook, it's time to send data back to Clarify.\n",
        "\n",
        "Writing data to Clarify is done in two steps:\n",
        "* Create a new `Signal`\n",
        "* Add data to the new `Signal`\n",
        "\n",
        "Writing meta data can be done by creating a `Signal` and populating it with meta data. The ID of this `Signal` needs to correspond with the ID we use for writing values to it.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/clarify/data-science-tutorials/main/media/introduction/light-2.png\" alt=\"clarify doodle\" width=\"400\">\n",
        "\n",
        "#### Create a new Signal\n",
        "The new `Signal` will contain a simple rolling window based on the `Item` we visualized above. First we want to create the meta data for the `Signal` with a `Signal` data structure.\n",
        "\n",
        "> *Why do we have both `Signals` and `Items`?*<br>\n",
        "> Signals map to the raw sensor that they are recieving data from. They are supposed to be a 1 to 1 mapping in the `Signals` meta data. `Items` is an abstraction of the `Signal`. The `Item` can have custom meta data and even consist of several `Signals`. \n",
        ">\n",
        "> *Why would you connect several `Signals` to an `Item`?* <br>\n",
        "> You might change sensors, or even connect a new one to an `Item`. To keep the historical values you can also connect several `Signal`. Clarify will even support *Calculated Items* in the future, which is aggregated from a combination of one or more items.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo3v8yTJrWBK",
        "outputId": "d134b42c-abd3-4520-8478-6a13f14b9972"
      },
      "outputs": [],
      "source": [
        "from pyclarify import SignalInfo\n",
        "new_signal_name = f\"{item_name}_rolling_mean\"\n",
        "input_id = f\"{item_id}_rolling_mean\"\n",
        "\n",
        "\n",
        "new_signal_meta_data = SignalInfo(\n",
        "    name=new_signal_name,\n",
        "    description=f\"Rolling window with 1d resolution of the signal {item_id}\",\n",
        "    labels={\n",
        "        \"rolling_window\": [\"1 day\"],\n",
        "        \"aggregated\": [True],\n",
        "        \"aggregated_from\": [item_id]\n",
        "    },\n",
        ")\n",
        "\n",
        "save_signal_request = {\n",
        "    \"inputs\": {\n",
        "        input_id : new_signal_meta_data\n",
        "    },\n",
        "    \"createOnly\": False \n",
        "    #False = create new signal if none with the id exists, True = update existing signal\n",
        "}\n",
        "\n",
        "response = client.save_signals(save_signal_request)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVeLntqCzH4j"
      },
      "source": [
        "From the response you can see that you have a new `Input ID` and a `Signal ID`. The `Input ID` is the id we will use when selecting the signal we want to write to and the `Signal ID` is only used internally in Clarify and can be disregarded.\n",
        "\n",
        "> You can now see the `Signal` in Clarify by going to the integration menu and clicking `Show Signals`\n",
        "<img src=\"https://raw.githubusercontent.com/clarify/data-science-tutorials/main/media/introduction/open_signals.gif\" alt=\"Getting credentials\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22ab0910",
      "metadata": {},
      "source": [
        "#### Reading the new Signal\n",
        "Previously we have used the `select_items` method to read data. This is the normal way of reading data as `Items` are displayed in Clarify and used in timeseries. However, you can also read directly from signals using the `select_signal` method. Below is a code snippet to see the newly created signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60da7229",
      "metadata": {},
      "outputs": [],
      "source": [
        "select_signal_request = {\n",
        "    \"signals\": {\n",
        "        \"include\": True,\n",
        "        \"filter\": {\n",
        "            \"id\": {\n",
        "                \"$in\": [\n",
        "                   signal_id\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"items\": {\n",
        "        \"include\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "response = client.select_signals(select_signal_request)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "217aaa7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "for value in response.result.signals[signal_id]:\n",
        "    print(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7AD4SyPzNZ5"
      },
      "source": [
        "<a name=\"process\"></a>\n",
        "#### Add data to the new Signal\n",
        "As mentioned we want to write data to this `Signal`. We can use the popular library [Pandas](https://github.com/pandas-dev/pandas) to create a rolling average with a 1 day interval of the data retrieved in [reading values](#reading_values). Then, we will write these values to the newly created `Signal`.\n",
        "\n",
        "Let us start by importing `pandas` and creating a new Data Frame with rolling average. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "c7fWhy7rh7IN",
        "outputId": "94be8129-3fca-4802-f1d4-38d95de7980d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.options.plotting.backend = \"plotly\"\n",
        "df = pd.DataFrame(series)\n",
        "df.index = times\n",
        "\n",
        "df_rolling_mean = df.rolling('1d').mean()\n",
        "df_rolling_mean.columns=[input_id]\n",
        "merged_df = df.join(df_rolling_mean)\n",
        "merged_df.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smZZmtIMzmYs"
      },
      "source": [
        "As mentioned, we use data frames (not to be confused with pandas data frames) to send values to and from Clarify. [Data frames](https://docs.clarify.io/reference#data-frame-1) separates time and values by having the same timestamps for all signal even though they might not have a value at a given timestamp. The backend handles this by not writing null values to Clarify. The signals is a dictionary consiting of `input ids` as keys and values as values. \n",
        "\n",
        "To do this we take the index of the `pandas` data frame as timestamps and store them in an array called `times`, and convert the values to a dictionary called `series`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I21lixW0tAGq",
        "outputId": "e1147a3a-7b2a-485a-f228-a546aad12321"
      },
      "outputs": [],
      "source": [
        "from pyclarify import DataFrame\n",
        "times = df_rolling_mean.index.values.tolist()\n",
        "series = df_rolling_mean.to_dict(orient=\"list\")\n",
        "new_df = DataFrame(times=times, series=series)\n",
        "print(new_df.series)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIpJOIO1nxcV"
      },
      "source": [
        "Then we send this newly created data frame to Clarify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZERi9XjT1XjY",
        "outputId": "c30959d5-ec0d-4ce1-cda4-1a23cb839de6"
      },
      "outputs": [],
      "source": [
        "response = client.insert(new_df)\n",
        "print(response)\n",
        "#save the resource id for later\n",
        "resource_id = response.result.signalsByInput[percentile_input_id].id "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGKrdFdTn48T"
      },
      "source": [
        "Before we look at the data we have inserted into Clarify, we should check out one last data type called `Enums`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL3r7RTaEWNO"
      },
      "source": [
        "#### ENUMS\n",
        "Enums are a special type of input you can create that acts a little different. Enums are displayed as blocks of data with a single value. This makes it great for displaying events over a certain space of time. To keep things simple we will create 3 different enums for percentiles of the data. \n",
        "\n",
        "We follow the sampe procedure as above by first creating a new `Signal` and populating it with meta data. \n",
        "\n",
        "> Enums are stored as integers or rounded floats in Clarify. If you want to map these enums to strings e.g. `\"normal\"`, you can do so by specifying the `type` to be `\"enum\"` and setting `enumValues` to be a the mapping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9dy9Na32IxF"
      },
      "outputs": [],
      "source": [
        "# create signal\n",
        "percentile_signal_name = f\"{item_name}_percentile\"\n",
        "percentile_input_id = f\"{item_id}_percentile\"\n",
        "\n",
        "\n",
        "percentile_signal_meta_data = SignalInfo(\n",
        "    name=percentile_signal_name,\n",
        "    description=f\"Percentile enums of the signal {item_id}\",\n",
        "    labels={\n",
        "        \"percentiles\": [\"90\", \"75\"],\n",
        "        \"aggregated\": [True],\n",
        "        \"aggregated_from\": [item_id]\n",
        "    },\n",
        "    type=\"enum\",\n",
        "    enumValues={\n",
        "        \"0\": \"normal\",\n",
        "        \"1\": \"P75\",\n",
        "        \"2\": \"P95\"\n",
        "    }\n",
        ")\n",
        "\n",
        "save_enum_signal_request = {\n",
        "    \"inputs\":{\n",
        "        percentile_input_id : percentile_signal_meta_data\n",
        "    },\n",
        "    \"createOnly\":False\n",
        "}\n",
        "\n",
        "response = client.save_signals(save_enum_signal_request)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxV7f4jZo4eP"
      },
      "source": [
        "Now lets create the values of the series. We will do so by using pandas [quantile](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html) method. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pdoDOq6EVbr"
      },
      "outputs": [],
      "source": [
        "# set all enums to be zero\n",
        "merged_df[percentile_input_id] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Rp8hjEN8YoT"
      },
      "outputs": [],
      "source": [
        "# set values above 75th percentile to be one\n",
        "percentile_75 = df.quantile(q=0.75).values[0]\n",
        "merged_df.loc[merged_df[item_id] > percentile_75, percentile_input_id] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKWYAWZP8BS0"
      },
      "outputs": [],
      "source": [
        "# set values above 95th percentile to be two\n",
        "percentile_95 = df.quantile(q=0.95).values[0]\n",
        "merged_df.loc[merged_df[item_id] > percentile_95, percentile_input_id] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "JbCpdzWM5K6d",
        "outputId": "11b36bac-dc10-447a-ba3c-2374b87024fc"
      },
      "outputs": [],
      "source": [
        "merged_df.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hqdf4ItoGTe"
      },
      "source": [
        "Again, we follow the same procedure as above by inserting into Clarify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME2ioxus_Z1k",
        "outputId": "73ef255a-a721-4a93-fe6d-6ebeb8d0852f"
      },
      "outputs": [],
      "source": [
        "from pyclarify import DataFrame\n",
        "times = merged_df.index.values.tolist()\n",
        "series = {\n",
        "    percentile_input_id: merged_df[percentile_input_id].values.tolist()\n",
        "}\n",
        "new_df = DataFrame(times=times, series=series)\n",
        "print(new_df.series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJLflOyk_aV_",
        "outputId": "f4737670-7fd7-4682-937b-3a583cbc089b"
      },
      "outputs": [],
      "source": [
        "response = client.insert(new_df)\n",
        "print(response)\n",
        "#save the resource id for later\n",
        "resource_id = response.result.signalsByInput[percentile_input_id].id "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0aVzGa5TeUf"
      },
      "source": [
        "<a name=\"bonus\"></a>\n",
        "## Visualise the data in Clarify\n",
        "\n",
        "Once your data has been sent to Clarify, it should show up in the `Admin panel` as a `Signal` in your `Integration`.\n",
        "\n",
        "Publish your `Signal` to make it available as an `Item` in Clarify.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN3L0Rjjv4ED"
      },
      "source": [
        "#### Publishing Signals\n",
        "To view the data we have added in Clarify we need to publish the `Signals`. \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/clarify/data-science-tutorials/main/media/introduction/publish_signals.gif\" alt=\"publishing signals\">\n",
        "\n",
        "1. Go to Admin -> Integrations\n",
        "2. Click `Show Signals`\n",
        "3. Click on a newly created signal\n",
        "4. Click `Publish`\n",
        "\n",
        "\n",
        "You can also publish signals through the SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcda0d2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# pass some metadata from the signal to the item\n",
        "data_source = \"my data source\"\n",
        "location = [\"Trondheim\", \"Norway\"]\n",
        "\n",
        "if \"data-source\" in meta_data.labels.keys():\n",
        "  data_source = meta_data.labels[\"data-source\"]\n",
        "\n",
        "if \"location\" in meta_data.labels.keys():\n",
        "  location = meta_data.labels[\"location\"]\n",
        "\n",
        "percentile_item_meta_data = SignalInfo(\n",
        "    name=\"Percentile Enums\",\n",
        "    description=f\"Percentile enums of the signal {item_id}\",\n",
        "    labels={\n",
        "        \"location\": location,\n",
        "        \"data-source\": data_source,\n",
        "        \"percentiles\": [\n",
        "            \"90\", \n",
        "            \"75\", \n",
        "            \"normal\"\n",
        "        ],\n",
        "        \"aggregated\": [True],\n",
        "        \"aggregated_from\": [item_id],\n",
        "        \"published_automatically\": [True],\n",
        "        \"SDK_version\": [\"0.2.2\"]\n",
        "    },\n",
        "    type=\"enum\",\n",
        "    enumValues={\n",
        "        \"0\": \"normal\",\n",
        "        \"1\": \"P75\",\n",
        "        \"2\": \"P95\"\n",
        "    },\n",
        "    gapDetection= \"PT1H\"\n",
        ")\n",
        "response = client.publish_signals(\n",
        "    params={\n",
        "        \"itemsBySignal\": {resource_id: percentile_item_meta_data},\n",
        "        \"createOnly\": False,\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beq3FPc5A-uT"
      },
      "source": [
        "### Creating a timeline\n",
        "\n",
        "Now that all your newly created data is available you can create your very own timeline. \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/clarify/data-science-tutorials/main/media/introduction/create_timeline.gif\" alt=\"Getting credentials\">\n",
        "\n",
        "Steps:\n",
        "1. Go to Admin -> Items\n",
        "2. Select newly published Item\n",
        "3. Click `Open in Clarify`\n",
        "4. Click `Open in New Timeline`\n",
        "5. Add other Items by searching in the menu.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QRIVsigB8X-"
      },
      "source": [
        "**Where to go next**\n",
        "\n",
        "*   [Forecasting](https://colab.research.google.com/github/clarify/data-science-tutorials/blob/main/tutorials/Forecasting.ipynb)\n",
        "*   [Pattern Recognition](https://colab.research.google.com/github/clarify/data-science-tutorials/blob/main/tutorials/Pattern%20Recognition.ipynb)\n",
        "*   [Hosting with Google Cloud](https://colab.research.google.com/github/clarify/data-science-tutorials/blob/main/tutorials/Google%20Cloud%20Hosting.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome to PyClarify",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
