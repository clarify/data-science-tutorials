{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "forecasting.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "aa14c21647fac57b3856d88b60f59e423e5dc36172c1e0b60404c5a955b6de41"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Clarify Logo](https://global-uploads.webflow.com/5e81e464dad44d3a9a32d1f4/5ed10fc3f1ff8467f4466786_logo.svg)\n",
        "\n",
        "\n",
        "# Welcome to the Clarify Forecast tutorial! ðŸ“ˆ \n",
        "\n",
        "This notebook start from the point that you can get credentials, authentication token, and read data directly from Clarify, and then proceed to show how to perform forecasting and writting the result back into Clarify.\n",
        "\n",
        "<img src=\"../media/forecast/analysis_work.jpg\" alt=\"Additional Options\" style=\"width: 60%;\" />\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites \n",
        "* [Basic tutorial on using Python with Clarify](https://colab.research.google.com/github/searis/data-science-tutorials/blob/main/tutorials/Introduction.ipynb)\n",
        "    - Check this tutorial for more details about reading and writting data using the PyClarify interface\n",
        "\n",
        "\n",
        "## What you need\n",
        "* [Clarify](https://www.clarify.io) Account (with admin rights)\n",
        "* Credential file `clarify-credentials.json` from Clarify, available to the environment runnning this notebook.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What we will do\n",
        "\n",
        "1. [Initial setup](#read)\n",
        "    - [Reading meta-data](#nit_read_meta)\n",
        "    - [Reading data](#nit_read_data)\n",
        "2. [Forecasting](#apply)\n",
        "    - [Single signal forecasting](#apply-single)\n",
        "3. [Write the forecast in Clarify](#write)\n",
        "4. [Visualize the forecast result and collaborate with Clarify](#visualize)\n",
        "\n",
        "---\n",
        "Other resources:\n",
        "* [Other tutorials on using Python with Clarify](https://github.com/searis/data-science-tutorials/)\n",
        "* [API reference](https://docs.clarify.io/reference/http)\n",
        "* [SDK documentation](https://searis.github.io/pyclarify/)\n",
        "* [Merlion - time-series forecast and anomaly detection library](https://opensource.salesforce.com/Merlion/v1.0.1/tutorials.html)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name=\"init\"></a>  Initial setup\n",
        "We will be using the PyClarify SDK for authentication, reading and writing signals to the Clarify app. The SDK is mirroring the Clarify API, thus [the reference document](https://docs.clarify.io/reference) will be a good resource if you come across any issues or want to see the capabilities of the API. "
      ],
      "metadata": {
        "id": "cYHDIZHemDfW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# install dependencies\n",
        "!pip install requests pyclarify pandas matplotlib salesforce-merlion "
      ],
      "outputs": [],
      "metadata": {
        "id": "bZLi0pmmSKZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17249e6f-ab93-4fb7-838c-7203bdf6b5a2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from pyclarify import APIClient\n",
        "client = APIClient(\"./clarify-credentials.json\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "pc_0NantSKZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name=\"init_read_meta\"></a> Reading meta-data\n",
        "You can retrieve the items data and meta-data from the Clarify API. This is useful in case you want to have a list of items that you have access in the script you are running. Also the items id are necessary when retrieving data from Clarify."
      ],
      "metadata": {
        "id": "A8u-s7zYn3cH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from pyclarify.models.requests import ItemSelect\n",
        "empty_request = {\n",
        "  \"items\": {\n",
        "    \"include\": True, \n",
        "  }, \n",
        "  \"times\": {\n",
        "  }, \n",
        "  \"series\": {\n",
        "  }\n",
        "}\n",
        "meta_data_params = ItemSelect(**empty_request)"
      ],
      "outputs": [],
      "metadata": {
        "id": "rJZi9YXvVr6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the result we call the method `select_items` with returns a JSON with a field `result` and sub-field `items` with a dictionary of item ids and metadata. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "response = client.select_items(meta_data_params)\n",
        "signal_dict = response.result.items\n",
        "for signal, meta_data in signal_dict.items():\n",
        "  print(f\"ID: {signal} \\t Name: {meta_data.name}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "qOeAxI74VhLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c73f05-e1db-44ac-db80-db78302d0678"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default behavior of the `select_items` method is to return a list of items limit defined by the API. If you want to list all items that you have access to, you can iterate over the result list and make subsequent calls to the API asking to skip an amount of items given by the `skip` parameter. We will show an example of how to list all the items that you have access to. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name=\"init_read_data\"></a> Reading data\n",
        "\n",
        "Now, given the list of items that you have access to, you can choose one id of interest to retrieve data from."
      ],
      "metadata": {
        "id": "63xdOnC0rksb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "item_id = \"<item_id>\" #change for the you item_id\n",
        "\n",
        "reading_data_request = {\n",
        "  \"items\": {\n",
        "    \"include\": True,\n",
        "    \"filter\": {\n",
        "      \"id\": {\n",
        "        \"$in\": [\n",
        "          item_id\n",
        "        ]\n",
        "      }\n",
        "    }\n",
        "  },\n",
        "  \"times\": {\n",
        "    \"notBefore\": \"2021-08-07T07:14:19Z\" #starting from \n",
        "  },\n",
        "  \"series\": {\n",
        "    \"items\": True,\n",
        "    \"aggregates\": False\n",
        "  }\n",
        "}\n",
        "\n",
        "data_params = ItemSelect(**reading_data_request)\n",
        "\n",
        "response = client.select_items(data_params)\n",
        "item_name = list(response.result.items.values())[0].name\n",
        "times = response.result.data.times\n",
        "series = response.result.data.series"
      ],
      "outputs": [],
      "metadata": {
        "id": "XkZXG6zOZ3hG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We procced by converting the data from our internal `DataFrame` structure to `pandas.DataFrame` in order to use in the forecasting library. We also discard that timezone information because the forecasting library does not support timezones, we can save that information for later when inserting the forecast data back into Clarify. The following figure shows an example graph that we obtained by running the code for plotting with a particular signal, you should expect a similar looking one with your own data.\n",
        "\n",
        "<img src=\"../media/forecast/example_data_graph.png\" alt=\"Additional Options\" style=\"width: 40%;\" />"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(series)\n",
        "df.index = [time.replace(tzinfo=None) for time in times]\n",
        "if len(times) > 0:\n",
        "    tzinfo = times[0].tzinfo\n",
        "df.plot()\n",
        "print(len(times))"
      ],
      "outputs": [],
      "metadata": {
        "id": "SYtdgTgBebfT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4121cab9-ef77-4cce-b3cd-48069507b17d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name=\"apply\"></a> Forecasting\n",
        "\n",
        "Given a sequence values in a time window, we might wonder that could be likely possible values on that timeseries. The task of forecasting values of a timeseries is defined as a task where taking the values until a certain time, we predict possible future values for the timeseries. \n",
        "\n",
        "In order to do so, we will start by exploring the forecast models available in the library [`merlion`](https://opensource.salesforce.com/Merlion/v1.0.0/index.html). This library encapsulates multiple forecast methods, for for single signals, multiple signals and allow for easy modular experimentation with the algorithms, as well as composing and creating ensembles. We will only show the basic functionality here."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name=\"apply_single\"></a> Single signal forecasting\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic elements for using the `merlion` forecasting library is the `TimeSeries` data structure, transformations to the data, and the configuration and forecasting model. In this case we choose to use the `Prophet` forecasting model, which means that we need to instantiate a `ProphetConfig` object, defining for example the maximum forecast steps, seasonality and transformation on the data (which is this case is the `Identity` transformation). \n",
        "\n",
        "In order to visualize and validade the forecast we split the original time-series data into *train* and *test* splits. The variable `number_test_points` is used to define the number of points to be assigned to test, while the remaining part of the split is used for training. The model is trained using only the *training* split, and then evaluated in the held-out *testing* split.\n",
        "\n",
        "> For an in-depth tutorial of forecasting using `merlion` check the [official documentation](https://opensource.salesforce.com/Merlion/v1.0.1/examples/forecast/1_ForecastFeatures.html). You will find there information about the different models, forecasting with multiple time-series and anomaly detection.\n",
        "> For more about time-series train/test splitting methods including cross validation, you can check this tutorial [Time based cross validation](https://towardsdatascience.com/time-based-cross-validation-d259b13d42b8)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from merlion.utils import TimeSeries\n",
        "from merlion.models.forecast.prophet import Prophet, ProphetConfig\n",
        "from merlion.transform.base import Identity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "number_test_points = 150\n",
        "\n",
        "test_data = TimeSeries.from_pd(df[-number_test_points:])\n",
        "train_data = TimeSeries.from_pd(df[0:-number_test_points])\n",
        "config = ProphetConfig(max_forecast_steps=50, add_seasonality=\"auto\", transform=Identity())\n",
        "model  = Prophet(config)\n",
        "model.train(train_data=train_data)\n",
        "test_pred, test_err = model.forecast(time_stamps=test_data.time_stamps)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we collect the forecast values together with the training values, and call the plotting function, asking as well for the uncertainty around the forecast values. This is all done by calling the function `model.plot_forecast`. The following picture is an example of a graph obtained by runnning this code for a given signal. Once you run the notebook with your signal you will obtain a different graph, but with a similar look and elements. \n",
        "\n",
        "<img src=\"../media/forecast/example_prediction_graph.png\" alt=\"Additional Options\" style=\"width: 60%;\" />\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fig, ax = model.plot_forecast(time_series_prev =train_data,time_series=test_data, plot_forecast_uncertainty=True, plot_time_series_prev=True)\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name=\"write\"></a> Write the forecast in Clarify\n",
        "\n",
        "We can now write back to Clary by creating DataFrames and metadata for the generated forecast and calling the method `insert` from `pyclarify`. In this case we write both the main trend of the forecast, as well as the upper and lower limit associated with the uncertainty of the forecast."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from pyclarify import Signal, DataFrame\n",
        "\n",
        "config_dict = config.to_dict()\n",
        "config_labels=[str({x:config_dict[x]}) for x in config_dict]\n",
        "\n",
        "def write_data_and_metadata(original, new_signal_id, new_name, times, values):\n",
        "    args = { \"name\" : new_name, \"description\" : f\"Forecast for {original}\",\n",
        "    \"labels\" : {\n",
        "        \"original_item_id\":[original], \n",
        "        \"number_points_testing\": [number_test_points], \n",
        "        \"forecast_method\" :[ \"Prophet\"],\n",
        "        \"method_config\":config_labels}}\n",
        "\n",
        "    new_signal_meta_data = Signal(**args)\n",
        "\n",
        "    response = client.save_signals(\n",
        "        inputs={new_signal_id : new_signal_meta_data},\n",
        "        created_only=False #False = create new signal, True = update existing signal\n",
        "    )\n",
        "    series = {new_signal_id : values}\n",
        "    new_df = DataFrame(times=times, series=series)\n",
        "    response = client.insert(new_df)\n",
        "    print(response)\n",
        "\n",
        "forecast_column_id = test_pred.names[0]\n",
        "column_err = test_err.names[0]\n",
        "forecast_id=forecast_column_id +\"_pred\"\n",
        "forecast_id_upper=forecast_column_id +\"_upper\"\n",
        "forecast_id_lower=forecast_column_id +\"_lower\"\n",
        "\n",
        "forecast_values = test_pred.univariates[forecast_column_id].values\n",
        "forecast_upper_values= [x+y for x,y in zip(test_pred.univariates[forecast_column_id ].values, test_err.univariates[column_err].values)]\n",
        "forecast_lower_values= [x-y for x,y in zip(test_pred.univariates[forecast_column_id ].values, test_err.univariates[column_err].values)]\n",
        "\n",
        "write_data_and_metadata(item_id, forecast_id, f\"Forecast for {item_name }\", times=test_pred.time_stamps, values=forecast_values)\n",
        "write_data_and_metadata(item_id, forecast_id_upper, f\"Forecast for {item_name } (upper bound)\", times=test_err.time_stamps, values=forecast_upper_values)\n",
        "write_data_and_metadata(item_id, forecast_id_lower, f\"Forecast for {item_name } (lower bound)\", times=test_err.time_stamps, values=forecast_lower_values)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a result of the previous steps you should be able to find three new (or updated in case they already exist) signals under the integration that has been used in this tutorial, exemplified in the figure below.\n",
        "\n",
        "<img src=\"../media/forecast/saved_forecast.png\" alt=\"Additional Options\" style=\"width: 90%;\" />"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name=\"visualize\"></a> Visualize the forecast result and collaborate with Clarify\n",
        "<img src=\"../media/forecast/clarify_forecast_comment.png\" alt=\"Additional Options\"  />"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once your data is written via the Clarify API and you have created **items** for the forecast and the bounds of the interval characterizing the uncertainty of the forecast, you can create customized **timelines** with your data. Clarify facilitates the creation of dynamic and responsive graph visualization and collaboration around the generated forecast, for example with the possibility of creating threads of comments on a point or interval of time, as illustrated in the above figure. For more information about visualization and publishing signals on Clarify check the [basic tutorial on using Python with Clarify](https://colab.research.google.com/github/searis/data-science-tutorials/blob/main/tutorials/Introduction.ipynb)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Where to go next\n",
        "\n",
        "* [Pattern Recognition](https://colab.research.google.com/github/searis/data-science-tutorials/blob/main/tutorials/Pattern%20Recognition.ipynb)\n",
        "* [Google Cloud Hosting](https://colab.research.google.com/github/searis/data-science-tutorials/blob/main/tutorials/Google%20Cloud%20Hosting.ipynb)"
      ],
      "metadata": {}
    }
  ]
}